{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://dev.to/m_nevin/facial-analysis-with-python-and-amazon-rekognition-2il9\n",
    "\n",
    "https://docs.aws.amazon.com/code-samples/latest/catalog/code-catalog-python-example_code-rekognition.html\n",
    "\n",
    "\n",
    "https://docs.aws.amazon.com/rekognition/latest/dg/images-displaying-bounding-boxes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Create a Rekognition client\n",
    "client=boto3.client('rekognition','eu-west-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data on S3\n",
    "The way to store blobs on AWS - to use with Rekognition we just specify the bucket and file, pass it to Rekognition through our client and get our response.\n",
    "\n",
    "* Make sure you have your S3 Bucket, your accounts settings and rekognition in the same region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.detect_faces(\n",
    "    Image={\n",
    "         'S3Object':{\n",
    "             'Bucket':'nsadawi-aws-s3',\n",
    "             'Name':'49015677_2339570492995844_8862427911626424320_n.jpg'\n",
    "          }\n",
    "     },\n",
    "    Attributes=['ALL']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/csstnns/Desktop/Yam.jpeg\", 'rb') as image:\n",
    "    response = client.detect_faces(Image={\n",
    "        'Bytes': image.read()\n",
    "     },\n",
    "     Attributes=['ALL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Emotions\n",
    "for faceDetail in response['FaceDetails']:\n",
    "    print('Emotions: \\t Confidence\\n')\n",
    "    for emotion in faceDetail['Emotions']:\n",
    "        print(str(emotion['Type']) + '\\t\\t' + str(emotion['Confidence']))\n",
    "        #print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Details\n",
    "for faceDetail in response['FaceDetails']:\n",
    "    print(faceDetail['Eyeglasses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Bounding Box Around Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ExifTags, ImageColor\n",
    "\n",
    "def show_faces(photo,bucket): \n",
    "    \n",
    "    client=boto3.client('rekognition', region_name='eu-west-2')\n",
    "\n",
    "    # Load image from S3 bucket\n",
    "    s3_connection = boto3.resource('s3', region_name='eu-west-2')\n",
    "    s3_object = s3_connection.Object(bucket, photo)\n",
    "    s3_response = s3_object.get()\n",
    "\n",
    "    stream = io.BytesIO(s3_response['Body'].read())\n",
    "    image=Image.open(stream)\n",
    "    \n",
    "    #Call DetectFaces \n",
    "    response = client.detect_faces(Image={'S3Object': {'Bucket': bucket, 'Name': photo}},\n",
    "        Attributes=['ALL'])\n",
    "\n",
    "    imgWidth, imgHeight = image.size  \n",
    "    draw = ImageDraw.Draw(image)  \n",
    "                    \n",
    "\n",
    "    # calculate and display bounding boxes for each detected face       \n",
    "    print('Detected faces for ' + photo)    \n",
    "    for faceDetail in response['FaceDetails']:\n",
    "        print('The detected face is between ' + str(faceDetail['AgeRange']['Low']) \n",
    "              + ' and ' + str(faceDetail['AgeRange']['High']) + ' years old')\n",
    "        \n",
    "        box = faceDetail['BoundingBox']\n",
    "        left = imgWidth * box['Left']\n",
    "        top = imgHeight * box['Top']\n",
    "        width = imgWidth * box['Width']\n",
    "        height = imgHeight * box['Height']\n",
    "                \n",
    "\n",
    "        print('Left: ' + '{0:.0f}'.format(left))\n",
    "        print('Top: ' + '{0:.0f}'.format(top))\n",
    "        print('Face Width: ' + \"{0:.0f}\".format(width))\n",
    "        print('Face Height: ' + \"{0:.0f}\".format(height))\n",
    "\n",
    "        points = (\n",
    "            (left,top),\n",
    "            (left + width, top),\n",
    "            (left + width, top + height),\n",
    "            (left , top + height),\n",
    "            (left, top)\n",
    "\n",
    "        )\n",
    "        draw.line(points, fill='#00d400', width=2)\n",
    "\n",
    "        # Alternatively can draw rectangle. However you can't set line width.\n",
    "        #draw.rectangle([left,top, left + width, top + height], outline='#00d400') \n",
    "\n",
    "    image.show()\n",
    "\n",
    "    return len(response['FaceDetails'])\n",
    "\n",
    "def main():\n",
    "    bucket=\"nsadawi-aws-s3\"\n",
    "    photo=\"49015677_2339570492995844_8862427911626424320_n.jpg\"\n",
    "    \n",
    "    faces_count=show_faces(photo,bucket)\n",
    "    print(\"faces detected: \" + str(faces_count))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celebrity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/csstnns/Desktop/rm.png\", 'rb') as image:\n",
    "    response = client.recognize_celebrities(Image={\n",
    "        'Bytes': image.read()\n",
    "     })\n",
    "    #print(response)\n",
    "    # /Users/csstnns/Documents/viva3.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scence Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/csstnns/Desktop/rm.png\", 'rb') as image:\n",
    "    response = client.detect_labels(Image={\n",
    "        'Bytes': image.read()\n",
    "     })\n",
    "    #print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def compare_faces(sourceFile, targetFile):\n",
    "\n",
    "    client=boto3.client('rekognition', region_name='eu-west-2')\n",
    "   \n",
    "    imageSource=open(sourceFile,'rb')\n",
    "    imageTarget=open(targetFile,'rb')\n",
    "\n",
    "    response=client.compare_faces(SimilarityThreshold=80,\n",
    "                                  SourceImage={'Bytes': imageSource.read()},\n",
    "                                  TargetImage={'Bytes': imageTarget.read()})\n",
    "    \n",
    "    for faceMatch in response['FaceMatches']:\n",
    "        position = faceMatch['Face']['BoundingBox']\n",
    "        similarity = str(faceMatch['Similarity'])\n",
    "        print('The face at ' +\n",
    "               str(position['Left']) + ' ' +\n",
    "               str(position['Top']) +\n",
    "               ' matches with ' + similarity + '% confidence')\n",
    "\n",
    "    imageSource.close()\n",
    "    imageTarget.close()     \n",
    "    return len(response['FaceMatches'])          \n",
    "\n",
    "def main():\n",
    "    source_file='/Users/csstnns/Downloads/noureddin1.jpg'\n",
    "    target_file='/Users/csstnns/Downloads/noureddin123.jpg'\n",
    "    face_matches=compare_faces(source_file, target_file)\n",
    "    print(\"Face matches: \" + str(face_matches))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection of Text in Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def detect_text(photo, bucket):\n",
    "\n",
    "    client=boto3.client('rekognition', region_name='eu-west-2')\n",
    "\n",
    "    response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "                        \n",
    "    textDetections=response['TextDetections']\n",
    "    print ('Detected text\\n----------')\n",
    "    for text in textDetections:\n",
    "            print ('Detected text:' + text['DetectedText'])\n",
    "            print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "            print ('Id: {}'.format(text['Id']))\n",
    "            if 'ParentId' in text:\n",
    "                print ('Parent Id: {}'.format(text['ParentId']))\n",
    "            print ('Type:' + text['Type'])\n",
    "            print()\n",
    "    return len(textDetections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='nsadawi-aws-s3'\n",
    "photo='realmadrid.png'\n",
    "text_count=detect_text(photo,bucket)\n",
    "print(\"Text detected: \" + str(text_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
