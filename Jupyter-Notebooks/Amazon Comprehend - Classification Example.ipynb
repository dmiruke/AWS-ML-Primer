{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Comprehend - Classification Example\n",
    "### Classify using Text Features\n",
    "\n",
    "Objective: Train a model to identify tweets that require followup  \n",
    "\n",
    "Input: Tweets  \n",
    "Target: Binary. 0=Normal, 1=Followup\n",
    "\n",
    "\n",
    "\n",
    "#### AWS Twitter Labelled Tweets are available in this bucket: \n",
    "#### https://s3.console.aws.amazon.com/s3/buckets/aml-sample-data/?region=us-east-2\n",
    "####   File:  social-media/aml_training_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Twitter training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://aml-sample-data/social-media/aml_training_dataset.csv ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training and Test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('aml_training_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rows: {0}, Columns: {1}'.format(df.shape[0],df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text','trainingLabel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainingLabel contains the class\n",
    "# Valid values are: \n",
    "#  0 = Normal\n",
    "#  1 = Followup\n",
    "\n",
    "df.trainingLabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_normal = df['trainingLabel'] == 0\n",
    "tweet_followup = df['trainingLabel'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some examples of tweets that are classified as requiring follow-up\n",
    "for i in range(15):\n",
    "    print(df[tweet_followup]['text'].iloc[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some examples of tweets that are classified as normal\n",
    "for i in range(10):\n",
    "    print(df[tweet_normal]['text'].iloc[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training, Validation and Test Split\n",
    "# Comprehend service automatically splits the provided dataset into 80-20 ratio for training and validation\n",
    "# We need to independently confirm quality of the model using a test set.\n",
    "\n",
    "# So, let's reserve 10% of the data for test and provide the remaining 90% to Comprehend service\n",
    "# Training & Validation   = 90% of the data\n",
    "# Test       = 10% of the data\n",
    "\n",
    "# Randomize the datset\n",
    "np.random.seed(5)\n",
    "l = list(df.index)\n",
    "np.random.shuffle(l)\n",
    "df = df.iloc[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df.shape[0]\n",
    "train = int(.9 * rows)\n",
    "test = rows - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:train]\n",
    "df_test = df[train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.trainingLabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.trainingLabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data .. Notice No Header and Label Before Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('twitter_train.csv',\n",
    "                index=False,\n",
    "                header=False,\n",
    "                columns=['trainingLabel','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('twitter_test_with_label.csv',\n",
    "                index=False,\n",
    "                header=False,\n",
    "                columns=['trainingLabel','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('twitter_test_without_label.csv',\n",
    "                index=False,\n",
    "                header=False,\n",
    "                columns=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify your bucket name. Replace 'chandra-ml-sagemaker' with your bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp twitter_train.csv s3://aws-ml-test-nsadawi/twitter/train/twitter_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp twitter_test_without_label.csv s3://aws-ml-test-nsadawi/twitter/test/twitter_test_without_label.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Running Classification Job on Comprehend\n",
    "### Copy tar gz file from S3\n",
    "#### Update the S3 path to point to the file in your bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp \"s3://aws-ml-test-nsadawi/twitter/test_output/479320215787-CLN-85177e7f1be27bbfa8eaa87eee9b8b0f/output/output.tar.gz\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tar file content\n",
    "import tarfile\n",
    "tar = tarfile.open(\"output.tar.gz\")\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = 'twitter_test_with_label.csv'\n",
    "predicted_file = 'predictions.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the column names as the file does not have column header\n",
    "df = pd.read_csv(test_file,names=['trainingLabel','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = []\n",
    "predicted_prob = []\n",
    "\n",
    "with open(predicted_file,'r') as f:\n",
    "    l = f.readline()\n",
    "    while (l):\n",
    "        j = json.loads(l)\n",
    "        if j['Classes'][0]['Name'] == '0':            \n",
    "            predicted_class.append(0)\n",
    "            # Add positive class probability\n",
    "            predicted_prob.append(j['Classes'][1]['Score'])\n",
    "        else:\n",
    "            predicted_class.append(1)\n",
    "            # Add positive class probability\n",
    "            predicted_prob.append(j['Classes'][0]['Score'])\n",
    "        \n",
    "        l = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_prob[:5],predicted_prob[-5:])\n",
    "print(predicted_class[:5],predicted_class[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_class'] = predicted_class\n",
    "df['predicted_prob'] = predicted_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
